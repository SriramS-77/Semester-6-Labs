{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb496206",
   "metadata": {},
   "source": [
    "**Sriram Sunderrajan** <br>\n",
    "**220962444** <br>\n",
    "**Deep Learning Lab - Week 8** <br>\n",
    "**Long- Short Term Memory Network** <br>\n",
    "**CSE - AIML (A2 - 77)** <br>\n",
    "**1st April 2025** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9613ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599f9b8",
   "metadata": {},
   "source": [
    "## Question - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c44b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../Lab-8/Data/Natural Gas/daily_csv.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533d7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfcb7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5952\n",
      "1.05 18.48\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Preprocess the data - Drop NA values in the dataset\n",
    "df = df.dropna()\n",
    "\n",
    "y = df['Price'].values\n",
    "x = np.arange(1, len(y), 1)\n",
    "\n",
    "print(len(y))\n",
    "\n",
    "# Normalize the input range between 0 and 1\n",
    "minm = y.min()\n",
    "maxm = y.max()\n",
    "print(minm, maxm)\n",
    "\n",
    "y = (y - minm) / (maxm - minm)\n",
    "\n",
    "Sequence_Length = 10\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(0, 5900):\n",
    "    list1 = []\n",
    "    for j in range(i, i + Sequence_Length):\n",
    "        list1.append(y[j])\n",
    "        X.append(list1)\n",
    "        Y.append(y[j + 1])\n",
    "        \n",
    "#Convert from list to array\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "#Split the data as the train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,\n",
    "test_size=0.10, random_state=42, shuffle=False, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313c6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGT(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.len = x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx].to(device), self.y[idx].to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dataset = NGT(x_train,y_train)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset, shuffle=True, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5438de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=1, hidden_size=5, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=5, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output, _status = self.rnn(x)\n",
    "        output = output[:,-1,:]\n",
    "        output = self.fc1(torch.relu(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18881da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 th iteration :  tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "10 th iteration :  tensor(0.0111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "15 th iteration :  tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "20 th iteration :  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "25 th iteration :  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "30 th iteration :  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "35 th iteration :  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "40 th iteration :  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "45 th iteration :  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 th iteration :  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel().to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    for j, data in enumerate(train_loader):\n",
    "        y_pred = model(data[:][0].view(-1, Sequence_Length, 1)).reshape(-1)\n",
    "        loss = criterion(y_pred, data[:][1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if i % 5 == 0:\n",
    "        print(i, \"th iteration : \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65334593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set = NGT(x_test,y_test)\n",
    "test_pred = model(test_set[:][0].view(-1,10,1)).view(-1)\n",
    "\n",
    "plt.title(\"Predicted vs Actual Prices\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price of natural gas\")\n",
    "plt.plot(test_pred.detach().cpu().numpy(), label='predicted')\n",
    "plt.plot(test_set[:][1].view(-1).cpu(), label='original')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ded14",
   "metadata": {},
   "source": [
    "## Question - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585c37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import string\n",
    "\n",
    "names_dir_path = \"../Lab-8/Data/Names/data/names/\"\n",
    "\n",
    "class namesDataset(Dataset):\n",
    "    def __init__(self, dir, train_split=0.9, max_length=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train = True\n",
    "        self.data = []\n",
    "        \n",
    "        self.labelToLang = {}\n",
    "        \n",
    "        # Mapping of characters to integers\n",
    "        all_characters = string.ascii_lowercase\n",
    "        self.n_characters = len(all_characters)\n",
    "        self.char_to_index = {ch: i for i, ch in enumerate(all_characters)}\n",
    "        \n",
    "        file_names = glob(os.path.join(dir, \"*.txt\"))\n",
    "            \n",
    "        \n",
    "        for lang_idx, file_name in enumerate(file_names):\n",
    "            lang = file_name.split(\"/\")[-1][:-4]\n",
    "            self.labelToLang[lang_idx] = lang\n",
    "            \n",
    "            f = open(file_name, \"r\")\n",
    "            self.data += [([self.char_to_index.get(ch, 0) for ch in name[:-1].lower()], lang_idx) for name in f.readlines()]\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        \n",
    "        if self.max_length is None:\n",
    "            self.max_length = max([len(data_point[0]) for data_point in self.data])\n",
    "        \n",
    "        random.shuffle(self.data)\n",
    "        # print(self.data)\n",
    "        \n",
    "        self.train_data, self.test_data = self.data[:int(len(self.data) * train_split)], self.data[int(len(self.data) * train_split):]\n",
    "        print(len(self.train_data), len(self.test_data))\n",
    "        # print(self.test_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_data) if self.train else len(self.test_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name, label = self.train_data[idx] if self.train else self.test_data[idx]\n",
    "        \n",
    "        # Pad name to have fixed length\n",
    "        name = name[:self.max_length] + [0] * (self.max_length - len(name))\n",
    "        \n",
    "        return torch.Tensor(name).to(device), torch.tensor(label).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f919707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18066 2008\n"
     ]
    }
   ],
   "source": [
    "dataset = namesDataset(names_dir_path)\n",
    "\n",
    "train_loader = DataLoader(dataset, shuffle=False, batch_size=32)\n",
    "test_loader = DataLoader(dataset, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60658fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_characters = dataset.n_characters\n",
    "n_languages = len(dataset.labelToLang)\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, n_characters=n_characters, n_languages=n_languages, hidden_size=5):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        # self.embedding = nn.Embedding(n_characters, hidden_size)\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=5, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, n_languages)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.embedding(x)  # [batch_size, seq_len, hidden_size]\n",
    "        out, _ = self.lstm(x)  # Get the RNN output\n",
    "        # print(out.size(), out)\n",
    "        out = out[:, -1, :]  # Take the output of the last time step\n",
    "        # print(out.size(), out)\n",
    "        out = self.fc(out)  # Final linear layer for classification\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72834af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "\n",
    "learning_rate = 1e-3 * 5\n",
    "\n",
    "model = LanguageModel(n_characters=n_characters, n_languages=n_languages).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b0e7ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 1.8845, Accuracy: 46.55%\n",
      "Epoch [2/200], Loss: 1.8463, Accuracy: 46.87%\n",
      "Epoch [3/200], Loss: 1.8463, Accuracy: 46.87%\n",
      "Epoch [4/200], Loss: 1.8463, Accuracy: 46.87%\n",
      "Epoch [5/200], Loss: 1.8215, Accuracy: 46.94%\n",
      "Epoch [6/200], Loss: 1.6810, Accuracy: 49.61%\n",
      "Epoch [7/200], Loss: 1.6255, Accuracy: 50.24%\n",
      "Epoch [8/200], Loss: 1.5982, Accuracy: 51.41%\n",
      "Epoch [9/200], Loss: 1.5801, Accuracy: 52.09%\n",
      "Epoch [10/200], Loss: 1.5670, Accuracy: 52.59%\n",
      "Epoch [11/200], Loss: 1.5596, Accuracy: 53.19%\n",
      "Epoch [12/200], Loss: 1.5646, Accuracy: 52.93%\n",
      "Epoch [13/200], Loss: 1.5506, Accuracy: 53.60%\n",
      "Epoch [14/200], Loss: 1.5428, Accuracy: 53.88%\n",
      "Epoch [15/200], Loss: 1.5383, Accuracy: 54.13%\n",
      "Epoch [16/200], Loss: 1.5337, Accuracy: 54.44%\n",
      "Epoch [17/200], Loss: 1.5260, Accuracy: 54.62%\n",
      "Epoch [18/200], Loss: 1.5273, Accuracy: 54.74%\n",
      "Epoch [19/200], Loss: 1.5190, Accuracy: 54.91%\n",
      "Epoch [20/200], Loss: 1.5130, Accuracy: 55.00%\n",
      "Epoch [21/200], Loss: 1.5139, Accuracy: 54.83%\n",
      "Epoch [22/200], Loss: 1.4949, Accuracy: 55.91%\n",
      "Epoch [23/200], Loss: 1.4943, Accuracy: 56.22%\n",
      "Epoch [24/200], Loss: 1.4818, Accuracy: 56.77%\n",
      "Epoch [25/200], Loss: 1.4655, Accuracy: 57.41%\n",
      "Epoch [26/200], Loss: 1.4563, Accuracy: 57.83%\n",
      "Epoch [27/200], Loss: 1.4482, Accuracy: 58.13%\n",
      "Epoch [28/200], Loss: 1.4456, Accuracy: 58.18%\n",
      "Epoch [29/200], Loss: 1.4471, Accuracy: 58.21%\n",
      "Epoch [30/200], Loss: 1.4346, Accuracy: 58.79%\n",
      "Epoch [31/200], Loss: 1.4286, Accuracy: 58.85%\n",
      "Epoch [32/200], Loss: 1.4218, Accuracy: 59.08%\n",
      "Epoch [33/200], Loss: 1.4271, Accuracy: 59.08%\n",
      "Epoch [34/200], Loss: 1.5446, Accuracy: 54.34%\n",
      "Epoch [35/200], Loss: 1.4653, Accuracy: 57.33%\n",
      "Epoch [36/200], Loss: 1.4495, Accuracy: 58.25%\n",
      "Epoch [37/200], Loss: 1.4390, Accuracy: 58.54%\n",
      "Epoch [38/200], Loss: 1.4269, Accuracy: 58.94%\n",
      "Epoch [39/200], Loss: 1.4277, Accuracy: 59.10%\n",
      "Epoch [40/200], Loss: 1.4142, Accuracy: 59.45%\n",
      "Epoch [41/200], Loss: 1.4134, Accuracy: 59.32%\n",
      "Epoch [42/200], Loss: 1.4054, Accuracy: 59.61%\n",
      "Epoch [43/200], Loss: 1.4072, Accuracy: 59.64%\n",
      "Epoch [44/200], Loss: 1.3953, Accuracy: 60.09%\n",
      "Epoch [45/200], Loss: 1.3983, Accuracy: 60.15%\n",
      "Epoch [46/200], Loss: 1.3912, Accuracy: 60.14%\n",
      "Epoch [47/200], Loss: 1.3844, Accuracy: 60.45%\n",
      "Epoch [48/200], Loss: 1.3773, Accuracy: 60.65%\n",
      "Epoch [49/200], Loss: 1.3713, Accuracy: 60.81%\n",
      "Epoch [50/200], Loss: 1.3772, Accuracy: 60.75%\n",
      "Epoch [51/200], Loss: 1.3701, Accuracy: 60.62%\n",
      "Epoch [52/200], Loss: 1.3630, Accuracy: 61.00%\n",
      "Epoch [53/200], Loss: 1.3529, Accuracy: 61.23%\n",
      "Epoch [54/200], Loss: 1.3573, Accuracy: 61.24%\n",
      "Epoch [55/200], Loss: 1.3556, Accuracy: 61.14%\n",
      "Epoch [56/200], Loss: 1.3468, Accuracy: 61.42%\n",
      "Epoch [57/200], Loss: 1.3457, Accuracy: 61.45%\n",
      "Epoch [58/200], Loss: 1.3452, Accuracy: 61.52%\n",
      "Epoch [59/200], Loss: 1.3485, Accuracy: 61.37%\n",
      "Epoch [60/200], Loss: 1.3402, Accuracy: 61.68%\n",
      "Epoch [61/200], Loss: 1.3233, Accuracy: 62.06%\n",
      "Epoch [62/200], Loss: 1.3402, Accuracy: 61.64%\n",
      "Epoch [63/200], Loss: 1.3487, Accuracy: 61.33%\n",
      "Epoch [64/200], Loss: 1.4843, Accuracy: 56.65%\n",
      "Epoch [65/200], Loss: 1.4007, Accuracy: 59.03%\n",
      "Epoch [66/200], Loss: 1.4313, Accuracy: 58.20%\n",
      "Epoch [67/200], Loss: 1.3956, Accuracy: 59.03%\n",
      "Epoch [68/200], Loss: 1.3961, Accuracy: 58.81%\n",
      "Epoch [69/200], Loss: 1.3735, Accuracy: 59.98%\n",
      "Epoch [70/200], Loss: 1.4209, Accuracy: 58.76%\n",
      "Epoch [71/200], Loss: 1.3834, Accuracy: 59.21%\n",
      "Epoch [72/200], Loss: 1.3528, Accuracy: 60.90%\n",
      "Epoch [73/200], Loss: 1.3258, Accuracy: 61.73%\n",
      "Epoch [74/200], Loss: 1.3150, Accuracy: 62.02%\n",
      "Epoch [75/200], Loss: 1.3158, Accuracy: 61.98%\n",
      "Epoch [76/200], Loss: 1.3252, Accuracy: 61.58%\n",
      "Epoch [77/200], Loss: 1.3135, Accuracy: 62.09%\n",
      "Epoch [78/200], Loss: 1.3000, Accuracy: 62.54%\n",
      "Epoch [79/200], Loss: 1.2988, Accuracy: 62.54%\n",
      "Epoch [80/200], Loss: 1.2891, Accuracy: 62.96%\n",
      "Epoch [81/200], Loss: 1.3083, Accuracy: 62.37%\n",
      "Epoch [82/200], Loss: 1.3039, Accuracy: 62.28%\n",
      "Epoch [83/200], Loss: 1.2888, Accuracy: 63.05%\n",
      "Epoch [84/200], Loss: 1.3060, Accuracy: 62.34%\n",
      "Epoch [85/200], Loss: 1.3938, Accuracy: 59.39%\n",
      "Epoch [86/200], Loss: 1.3474, Accuracy: 61.42%\n",
      "Epoch [87/200], Loss: 1.3385, Accuracy: 62.03%\n",
      "Epoch [88/200], Loss: 1.3405, Accuracy: 61.61%\n",
      "Epoch [89/200], Loss: 1.3250, Accuracy: 62.08%\n",
      "Epoch [90/200], Loss: 1.3107, Accuracy: 62.52%\n",
      "Epoch [91/200], Loss: 1.2888, Accuracy: 63.10%\n",
      "Epoch [92/200], Loss: 1.2940, Accuracy: 63.02%\n",
      "Epoch [93/200], Loss: 1.3189, Accuracy: 62.02%\n",
      "Epoch [94/200], Loss: 1.3246, Accuracy: 61.90%\n",
      "Epoch [95/200], Loss: 1.2866, Accuracy: 63.38%\n",
      "Epoch [96/200], Loss: 1.2874, Accuracy: 63.31%\n",
      "Epoch [97/200], Loss: 1.2782, Accuracy: 63.73%\n",
      "Epoch [98/200], Loss: 1.2650, Accuracy: 64.08%\n",
      "Epoch [99/200], Loss: 1.2656, Accuracy: 63.87%\n",
      "Epoch [100/200], Loss: 1.2820, Accuracy: 63.37%\n",
      "Epoch [101/200], Loss: 1.2604, Accuracy: 64.30%\n",
      "Epoch [102/200], Loss: 1.2824, Accuracy: 63.36%\n",
      "Epoch [103/200], Loss: 1.2792, Accuracy: 63.49%\n",
      "Epoch [104/200], Loss: 1.2603, Accuracy: 63.94%\n",
      "Epoch [105/200], Loss: 1.2619, Accuracy: 64.03%\n",
      "Epoch [106/200], Loss: 1.2509, Accuracy: 64.14%\n",
      "Epoch [107/200], Loss: 1.2625, Accuracy: 63.98%\n",
      "Epoch [108/200], Loss: 1.2528, Accuracy: 64.09%\n",
      "Epoch [109/200], Loss: 1.2816, Accuracy: 63.47%\n",
      "Epoch [110/200], Loss: 1.2610, Accuracy: 64.19%\n",
      "Epoch [111/200], Loss: 1.2459, Accuracy: 64.29%\n",
      "Epoch [112/200], Loss: 1.2369, Accuracy: 64.75%\n",
      "Epoch [113/200], Loss: 1.2574, Accuracy: 64.16%\n",
      "Epoch [114/200], Loss: 1.2390, Accuracy: 64.85%\n",
      "Epoch [115/200], Loss: 1.2319, Accuracy: 64.82%\n",
      "Epoch [116/200], Loss: 1.2388, Accuracy: 64.70%\n",
      "Epoch [117/200], Loss: 1.2204, Accuracy: 65.30%\n",
      "Epoch [118/200], Loss: 1.2301, Accuracy: 64.82%\n",
      "Epoch [119/200], Loss: 1.2310, Accuracy: 64.78%\n",
      "Epoch [120/200], Loss: 1.2537, Accuracy: 64.13%\n",
      "Epoch [121/200], Loss: 1.2783, Accuracy: 63.45%\n",
      "Epoch [122/200], Loss: 1.2374, Accuracy: 64.64%\n",
      "Epoch [123/200], Loss: 1.2309, Accuracy: 64.86%\n",
      "Epoch [124/200], Loss: 1.2668, Accuracy: 63.71%\n",
      "Epoch [125/200], Loss: 1.2151, Accuracy: 65.35%\n",
      "Epoch [126/200], Loss: 1.2209, Accuracy: 64.99%\n",
      "Epoch [127/200], Loss: 1.2413, Accuracy: 64.62%\n",
      "Epoch [128/200], Loss: 1.2243, Accuracy: 65.18%\n",
      "Epoch [129/200], Loss: 1.2135, Accuracy: 65.43%\n",
      "Epoch [130/200], Loss: 1.3203, Accuracy: 62.49%\n",
      "Epoch [131/200], Loss: 1.2810, Accuracy: 63.54%\n",
      "Epoch [132/200], Loss: 1.2556, Accuracy: 64.24%\n",
      "Epoch [133/200], Loss: 1.2678, Accuracy: 64.06%\n",
      "Epoch [134/200], Loss: 1.2752, Accuracy: 63.83%\n",
      "Epoch [135/200], Loss: 1.3372, Accuracy: 62.32%\n",
      "Epoch [136/200], Loss: 1.3010, Accuracy: 62.68%\n",
      "Epoch [137/200], Loss: 1.2772, Accuracy: 63.26%\n",
      "Epoch [138/200], Loss: 1.2816, Accuracy: 63.15%\n",
      "Epoch [139/200], Loss: 1.3320, Accuracy: 61.59%\n",
      "Epoch [140/200], Loss: 1.2853, Accuracy: 63.07%\n",
      "Epoch [141/200], Loss: 1.2842, Accuracy: 63.42%\n",
      "Epoch [142/200], Loss: 1.2696, Accuracy: 63.52%\n",
      "Epoch [143/200], Loss: 1.2926, Accuracy: 63.14%\n",
      "Epoch [144/200], Loss: 1.3103, Accuracy: 62.64%\n",
      "Epoch [145/200], Loss: 1.2881, Accuracy: 62.98%\n",
      "Epoch [146/200], Loss: 1.2730, Accuracy: 63.26%\n",
      "Epoch [147/200], Loss: 1.3178, Accuracy: 62.08%\n",
      "Epoch [148/200], Loss: 1.2506, Accuracy: 64.02%\n",
      "Epoch [149/200], Loss: 1.2360, Accuracy: 64.68%\n",
      "Epoch [150/200], Loss: 1.2708, Accuracy: 63.81%\n",
      "Epoch [151/200], Loss: 1.3163, Accuracy: 62.09%\n",
      "Epoch [152/200], Loss: 1.5048, Accuracy: 55.87%\n",
      "Epoch [153/200], Loss: 1.4186, Accuracy: 58.22%\n",
      "Epoch [154/200], Loss: 1.4074, Accuracy: 58.71%\n",
      "Epoch [155/200], Loss: 1.3918, Accuracy: 59.27%\n",
      "Epoch [156/200], Loss: 1.3617, Accuracy: 60.15%\n",
      "Epoch [157/200], Loss: 1.3806, Accuracy: 59.52%\n",
      "Epoch [158/200], Loss: 1.3973, Accuracy: 58.55%\n",
      "Epoch [159/200], Loss: 1.4129, Accuracy: 58.13%\n",
      "Epoch [160/200], Loss: 1.3683, Accuracy: 59.87%\n",
      "Epoch [161/200], Loss: 1.5359, Accuracy: 55.18%\n",
      "Epoch [162/200], Loss: 1.4516, Accuracy: 57.62%\n",
      "Epoch [163/200], Loss: 1.4144, Accuracy: 58.86%\n",
      "Epoch [164/200], Loss: 1.3922, Accuracy: 59.33%\n",
      "Epoch [165/200], Loss: 1.3750, Accuracy: 59.85%\n",
      "Epoch [166/200], Loss: 1.3556, Accuracy: 60.66%\n",
      "Epoch [167/200], Loss: 1.3521, Accuracy: 60.44%\n",
      "Epoch [168/200], Loss: 1.3577, Accuracy: 60.38%\n",
      "Epoch [169/200], Loss: 1.3472, Accuracy: 60.82%\n",
      "Epoch [170/200], Loss: 1.3523, Accuracy: 60.56%\n",
      "Epoch [171/200], Loss: 1.3468, Accuracy: 60.40%\n",
      "Epoch [172/200], Loss: 1.3234, Accuracy: 61.53%\n",
      "Epoch [173/200], Loss: 1.3664, Accuracy: 60.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/200], Loss: 1.3676, Accuracy: 59.63%\n",
      "Epoch [175/200], Loss: 1.3837, Accuracy: 59.48%\n",
      "Epoch [176/200], Loss: 1.3429, Accuracy: 61.11%\n",
      "Epoch [177/200], Loss: 1.3273, Accuracy: 61.11%\n",
      "Epoch [178/200], Loss: 1.3220, Accuracy: 61.55%\n",
      "Epoch [179/200], Loss: 1.3121, Accuracy: 61.75%\n",
      "Epoch [180/200], Loss: 1.3000, Accuracy: 62.26%\n",
      "Epoch [181/200], Loss: 1.2986, Accuracy: 62.48%\n",
      "Epoch [182/200], Loss: 1.2995, Accuracy: 62.45%\n",
      "Epoch [183/200], Loss: 1.2960, Accuracy: 62.32%\n",
      "Epoch [184/200], Loss: 1.2934, Accuracy: 62.83%\n",
      "Epoch [185/200], Loss: 1.2734, Accuracy: 63.26%\n",
      "Epoch [186/200], Loss: 1.2628, Accuracy: 63.33%\n",
      "Epoch [187/200], Loss: 1.3384, Accuracy: 61.00%\n",
      "Epoch [188/200], Loss: 1.3502, Accuracy: 60.55%\n",
      "Epoch [189/200], Loss: 1.2980, Accuracy: 62.34%\n",
      "Epoch [190/200], Loss: 1.2835, Accuracy: 62.71%\n",
      "Epoch [191/200], Loss: 1.2696, Accuracy: 63.16%\n",
      "Epoch [192/200], Loss: 1.2724, Accuracy: 63.09%\n",
      "Epoch [193/200], Loss: 1.2569, Accuracy: 63.44%\n",
      "Epoch [194/200], Loss: 1.2541, Accuracy: 63.79%\n",
      "Epoch [195/200], Loss: 1.3183, Accuracy: 62.02%\n",
      "Epoch [196/200], Loss: 1.2710, Accuracy: 63.39%\n",
      "Epoch [197/200], Loss: 1.2575, Accuracy: 64.03%\n",
      "Epoch [198/200], Loss: 1.2615, Accuracy: 63.64%\n",
      "Epoch [199/200], Loss: 1.2638, Accuracy: 63.61%\n",
      "Epoch [200/200], Loss: 1.2332, Accuracy: 64.94%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "dataset.train = True\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for names, labels in train_loader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        names = names.unsqueeze(2)\n",
    "        # labels = labels.unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(names)\n",
    "        \n",
    "        # print(labels.size(), outputs.size())\n",
    "        # outputs = nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # print(predicted, labels)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9901621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 64.49%\n"
     ]
    }
   ],
   "source": [
    "dataset.train = False\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for names, labels in test_loader:\n",
    "        names = names.unsqueeze(2)\n",
    "        outputs = model(names)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ed35264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: English\n",
      "Predicted: English\n",
      "\n",
      "Actual: English\n",
      "Predicted: English\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: English\n",
      "Predicted: English\n",
      "\n",
      "Actual: English\n",
      "Predicted: Chinese\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: German\n",
      "Predicted: English\n",
      "\n",
      "Actual: Korean\n",
      "Predicted: Chinese\n",
      "\n",
      "Actual: English\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Italian\n",
      "Predicted: English\n",
      "\n",
      "Actual: Japanese\n",
      "Predicted: English\n",
      "\n",
      "Actual: Italian\n",
      "Predicted: Italian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: English\n",
      "Predicted: English\n",
      "\n",
      "Actual: Arabic\n",
      "Predicted: Arabic\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Chinese\n",
      "Predicted: Chinese\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: English\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Italian\n",
      "Predicted: Italian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Chinese\n",
      "Predicted: Chinese\n",
      "\n",
      "Actual: Arabic\n",
      "Predicted: Arabic\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Arabic\n",
      "Predicted: Arabic\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Czech\n",
      "Predicted: English\n",
      "\n",
      "Actual: French\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Arabic\n",
      "Predicted: Italian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: English\n",
      "Predicted: Japanese\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Japanese\n",
      "Predicted: Arabic\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Arabic\n",
      "\n",
      "Actual: English\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Vietnamese\n",
      "Predicted: English\n",
      "\n",
      "Actual: Arabic\n",
      "Predicted: Arabic\n",
      "\n",
      "Actual: Czech\n",
      "Predicted: Chinese\n",
      "\n",
      "Actual: Spanish\n",
      "Predicted: English\n",
      "\n",
      "Actual: English\n",
      "Predicted: Russian\n",
      "\n",
      "Actual: Russian\n",
      "Predicted: Russian\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(50):\n",
    "        name, label = dataset[i]\n",
    "        name, label = torch.unsqueeze(name, 0), torch.unsqueeze(label, 0)\n",
    "        name = name.unsqueeze(2)\n",
    "        #print(name, label)\n",
    "        outputs = model(name)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # print(predicted)\n",
    "\n",
    "        print(\"Actual:\", dataset.labelToLang[label.detach().cpu().item()])\n",
    "        print(\"Predicted:\", dataset.labelToLang[predicted.detach().cpu().item()])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e61b19",
   "metadata": {},
   "source": [
    "## Question - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dff34bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00df9eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_6115/932619875.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  text = \"\"\"In one rearrangement proof, two squares are used whose sides have a measure of a + b and which contain four right triangles whose sides are a, b and c, with the hypotenuse being c. In the square on the right side, the triangles are placed such that the corners of the square correspond to the corners of the right angle in the triangles, forming a square in the center whose sides are length c. Each outer square has an area of ( a + b ) 2  well as 2 a b + c 2, with 2 a b representing the total area of the four triangles. Within the big square on the left side, the four triangles are moved to form two similar rectangles with sides of length a and b. These rectangles in their new position have now delineated two new squares, one having side length a is formed in the bottom-left corner, and another square of side length b formed in the top-right corner. In this new position, this left side now has a square of area ( a + b ) 2 as well as 2 a b + a 2 + b 2. Since both squares have the area of ( a + b ) 2 {\\displaystyle (a+b)^{2}} it follows that the other measure of the square area also equal each other such that 2 a b + c 2 {\\displaystyle 2ab+c^{2}} = 2 a b + a 2 + b 2 {\\displaystyle 2ab+a^{2}+b^{2}}. With the area of the four triangles removed from both side of the equation what remains is a 2 + b 2 = c 2 . {\\displaystyle a^{2}+b^{2}=c^{2}.} [2]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare the data\n",
    "text = \"\"\"In one rearrangement proof, two squares are used whose sides have a measure of a + b and which contain four right triangles whose sides are a, b and c, with the hypotenuse being c. In the square on the right side, the triangles are placed such that the corners of the square correspond to the corners of the right angle in the triangles, forming a square in the center whose sides are length c. Each outer square has an area of ( a + b ) 2  well as 2 a b + c 2, with 2 a b representing the total area of the four triangles. Within the big square on the left side, the four triangles are moved to form two similar rectangles with sides of length a and b. These rectangles in their new position have now delineated two new squares, one having side length a is formed in the bottom-left corner, and another square of side length b formed in the top-right corner. In this new position, this left side now has a square of area ( a + b ) 2 as well as 2 a b + a 2 + b 2. Since both squares have the area of ( a + b ) 2 {\\displaystyle (a+b)^{2}} it follows that the other measure of the square area also equal each other such that 2 a b + c 2 {\\displaystyle 2ab+c^{2}} = 2 a b + a 2 + b 2 {\\displaystyle 2ab+a^{2}+b^{2}}. With the area of the four triangles removed from both side of the equation what remains is a 2 + b 2 = c 2 . {\\displaystyle a^{2}+b^{2}=c^{2}.} [2]\n",
    "\n",
    "In another proof rectangles in the second box can also be placed such that both have one corner that correspond to consecutive corners of the square. In this way they also form two boxes, this time in consecutive corners, with areas a 2 {\\displaystyle a^{2}} and b 2 {\\displaystyle b^{2}}which will again lead to a second square of with the area 2 a b + a 2 + b 2 {\\displaystyle 2ab+a^{2}+b^{2}}.\n",
    "\n",
    "English mathematician Sir Thomas Heath gives this proof in his commentary on Proposition I.47 in Euclid's Elements, and mentions the proposals of German mathematicians Carl Anton Bretschneider and Hermann Hankel that Pythagoras may have known this proof. Heath himself favors a different proposal for a Pythagorean proof, but acknowledges from the outset of his discussion \"that the Greek literature which we possess belonging to the first five centuries after Pythagoras contains no statement specifying this or any other particular great geometric discovery to him.\"[3] Recent scholarship has cast increasing doubt on any sort of role for Pythagoras as a creator of mathematics, although debate about this continues.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecdb211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/10000], Loss: 0.1773\n",
      "Epoch [1000/10000], Loss: 0.0519\n",
      "Epoch [1500/10000], Loss: 0.0433\n",
      "Epoch [2000/10000], Loss: 0.0406\n",
      "Epoch [2500/10000], Loss: 0.0393\n",
      "Epoch [3000/10000], Loss: 0.0387\n",
      "Epoch [3500/10000], Loss: 0.0383\n",
      "Epoch [4000/10000], Loss: 4.2792\n",
      "Epoch [4500/10000], Loss: 0.0390\n",
      "Epoch [5000/10000], Loss: 0.0383\n",
      "Epoch [5500/10000], Loss: 0.0380\n",
      "Epoch [6000/10000], Loss: 0.0378\n",
      "Epoch [6500/10000], Loss: 0.0377\n",
      "Epoch [7000/10000], Loss: 0.0376\n",
      "Epoch [7500/10000], Loss: 0.0375\n",
      "Epoch [8000/10000], Loss: 0.0375\n",
      "Epoch [8500/10000], Loss: 0.0375\n",
      "Epoch [9000/10000], Loss: 0.0375\n",
      "Epoch [9500/10000], Loss: 0.0374\n",
      "Epoch [10000/10000], Loss: 0.0375\n",
      "Input text: \"Hello, this is a \" -> Predicted next character: \"o\"\n"
     ]
    }
   ],
   "source": [
    "# Create a set of all unique characters in the text\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "char_to_index = {ch: i for i, ch in enumerate(chars)}\n",
    "index_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Convert the text into numerical indices\n",
    "encoded_text = [char_to_index[ch] for ch in text]\n",
    "\n",
    "# Define sequence length (how many characters to look back to predict the next)\n",
    "sequence_length = 10\n",
    "\n",
    "# Prepare input-output pairs for training (X, y)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(encoded_text) - sequence_length):\n",
    "    X.append(encoded_text[i:i + sequence_length])\n",
    "    y.append(encoded_text[i + sequence_length])\n",
    "\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)\n",
    "\n",
    "# Step 2: Define the RNN model\n",
    "class NextCharacterRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NextCharacterRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Pass input through RNN layer\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Get the output from the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = vocab_size  # One-hot encoding of each character\n",
    "hidden_size = 128  # Number of RNN hidden units\n",
    "output_size = vocab_size  # Predict next character\n",
    "learning_rate = 0.001\n",
    "epochs = 10000\n",
    "\n",
    "# Model initialization\n",
    "model = NextCharacterRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Step 3: Train the model\n",
    "# Convert input sequences to one-hot encoding\n",
    "X_onehot = torch.zeros(X.size(0), X.size(1), vocab_size)\n",
    "\n",
    "for i in range(X.size(0)):\n",
    "    for j in range(X.size(1)):\n",
    "        X_onehot[i, j, X[i, j]] = 1\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_onehot)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Step 4: Predict next character\n",
    "def predict_next_char(model, input_text, char_to_index, index_to_char, sequence_length=10):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare the input sequence\n",
    "    input_indices = [char_to_index[ch] for ch in input_text[-sequence_length:]]\n",
    "    input_tensor = torch.zeros(1, sequence_length, vocab_size)\n",
    "\n",
    "    for i in range(sequence_length):\n",
    "        input_tensor[0, i, input_indices[i]] = 1\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        predicted_index = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    return index_to_char[predicted_index]\n",
    "\n",
    "# Test the model with a sequence of characters\n",
    "input_text = \"Hello, this is a \"\n",
    "predicted_char = predict_next_char(model, input_text, char_to_index, index_to_char)\n",
    "print(f'Input text: \"{input_text}\" -> Predicted next character: \"{predicted_char}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d00c6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \"other measure of \" -> Predicted next character: \"t\"\n",
      "Input text: \"other measure of t\" -> Predicted next character: \"h\"\n",
      "Input text: \"other measure of th\" -> Predicted next character: \"e\"\n",
      "Input text: \"other measure of the\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the \" -> Predicted next character: \"s\"\n",
      "Input text: \"other measure of the s\" -> Predicted next character: \"q\"\n",
      "Input text: \"other measure of the sq\" -> Predicted next character: \"u\"\n",
      "Input text: \"other measure of the squ\" -> Predicted next character: \"a\"\n",
      "Input text: \"other measure of the squa\" -> Predicted next character: \"r\"\n",
      "Input text: \"other measure of the squar\" -> Predicted next character: \"e\"\n",
      "Input text: \"other measure of the square\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the square \" -> Predicted next character: \"a\"\n",
      "Input text: \"other measure of the square a\" -> Predicted next character: \"r\"\n",
      "Input text: \"other measure of the square ar\" -> Predicted next character: \"e\"\n",
      "Input text: \"other measure of the square are\" -> Predicted next character: \"a\"\n",
      "Input text: \"other measure of the square area\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the square area \" -> Predicted next character: \"a\"\n",
      "Input text: \"other measure of the square area a\" -> Predicted next character: \"l\"\n",
      "Input text: \"other measure of the square area al\" -> Predicted next character: \"s\"\n",
      "Input text: \"other measure of the square area als\" -> Predicted next character: \"o\"\n",
      "Input text: \"other measure of the square area also\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the square area also \" -> Predicted next character: \"e\"\n",
      "Input text: \"other measure of the square area also e\" -> Predicted next character: \"q\"\n",
      "Input text: \"other measure of the square area also eq\" -> Predicted next character: \"u\"\n",
      "Input text: \"other measure of the square area also equ\" -> Predicted next character: \"a\"\n",
      "Input text: \"other measure of the square area also equa\" -> Predicted next character: \"l\"\n",
      "Input text: \"other measure of the square area also equal\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the square area also equal \" -> Predicted next character: \"e\"\n",
      "Input text: \"other measure of the square area also equal e\" -> Predicted next character: \"a\"\n",
      "Input text: \"other measure of the square area also equal ea\" -> Predicted next character: \"c\"\n",
      "Input text: \"other measure of the square area also equal eac\" -> Predicted next character: \"h\"\n",
      "Input text: \"other measure of the square area also equal each\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the square area also equal each \" -> Predicted next character: \"o\"\n",
      "Input text: \"other measure of the square area also equal each o\" -> Predicted next character: \"t\"\n",
      "Input text: \"other measure of the square area also equal each ot\" -> Predicted next character: \"h\"\n",
      "Input text: \"other measure of the square area also equal each oth\" -> Predicted next character: \"e\"\n",
      "Input text: \"other measure of the square area also equal each othe\" -> Predicted next character: \"r\"\n",
      "Input text: \"other measure of the square area also equal each other\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the square area also equal each other \" -> Predicted next character: \"s\"\n",
      "Input text: \"other measure of the square area also equal each other s\" -> Predicted next character: \"u\"\n",
      "Input text: \"other measure of the square area also equal each other su\" -> Predicted next character: \"c\"\n",
      "Input text: \"other measure of the square area also equal each other suc\" -> Predicted next character: \"h\"\n",
      "Input text: \"other measure of the square area also equal each other such\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the square area also equal each other such \" -> Predicted next character: \"t\"\n",
      "Input text: \"other measure of the square area also equal each other such t\" -> Predicted next character: \"h\"\n",
      "Input text: \"other measure of the square area also equal each other such th\" -> Predicted next character: \"a\"\n",
      "Input text: \"other measure of the square area also equal each other such tha\" -> Predicted next character: \"t\"\n",
      "Input text: \"other measure of the square area also equal each other such that\" -> Predicted next character: \" \"\n",
      "Input text: \"other measure of the square area also equal each other such that \" -> Predicted next character: \"t\"\n",
      "Input text: \"other measure of the square area also equal each other such that t\" -> Predicted next character: \"h\"\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a sequence of characters\n",
    "input_text = \"other measure of \"\n",
    "\n",
    "for i in range(50):\n",
    "    predicted_char = predict_next_char(model, input_text, char_to_index, index_to_char)\n",
    "    print(f'Input text: \"{input_text}\" -> Predicted next character: \"{predicted_char}\"')\n",
    "    input_text += predicted_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256411a0",
   "metadata": {},
   "source": [
    "## Question - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73542f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNModel,self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=1, hidden_size=5, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=5, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output, _status = self.rnn(x)\n",
    "        output = output[:,-1,:]\n",
    "        output = self.fc(torch.relu(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cece9892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 2.,  3.,  4.,  5.,  6.],\n",
       "         [ 3.,  4.,  5.,  6.,  7.],\n",
       "         [ 4.,  5.,  6.,  7.,  8.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [ 6.,  7.,  8.,  9., 10.],\n",
       "         [ 7.,  8.,  9., 10., 11.],\n",
       "         [ 8.,  9., 10., 11., 12.],\n",
       "         [ 9., 10., 11., 12., 13.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [11., 12., 13., 14., 15.],\n",
       "         [12., 13., 14., 15., 16.],\n",
       "         [13., 14., 15., 16., 17.],\n",
       "         [14., 15., 16., 17., 18.],\n",
       "         [15., 16., 17., 18., 19.],\n",
       "         [16., 17., 18., 19., 20.],\n",
       "         [17., 18., 19., 20., 21.],\n",
       "         [18., 19., 20., 21., 22.],\n",
       "         [19., 20., 21., 22., 23.]]),\n",
       " tensor([ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18.,\n",
       "         19., 20., 21., 22., 23., 24.]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = list(range(25))\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "for i in range(5, 25):\n",
    "    x.append(data[i-5:i])\n",
    "    y.append(data[i])\n",
    "    \n",
    "x, y = torch.Tensor(x), torch.Tensor(y)\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e3ab570",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8669e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.0837\n",
      "tensor([[23.3785]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [2/200], Loss: 0.0773\n",
      "tensor([[23.3696]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [3/200], Loss: 0.0653\n",
      "tensor([[23.3802]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [4/200], Loss: 0.0631\n",
      "tensor([[23.3812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [5/200], Loss: 0.0544\n",
      "tensor([[23.3808]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [6/200], Loss: 0.0533\n",
      "tensor([[23.3884]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [7/200], Loss: 0.0465\n",
      "tensor([[23.3817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [8/200], Loss: 0.0456\n",
      "tensor([[23.3934]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [9/200], Loss: 0.0401\n",
      "tensor([[23.3836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [10/200], Loss: 0.0393\n",
      "tensor([[23.3974]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [11/200], Loss: 0.0350\n",
      "tensor([[23.3869]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [12/200], Loss: 0.0341\n",
      "tensor([[23.4007]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [13/200], Loss: 0.0312\n",
      "tensor([[23.3919]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [14/200], Loss: 0.0303\n",
      "tensor([[23.4033]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [15/200], Loss: 0.0293\n",
      "tensor([[23.3991]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [16/200], Loss: 0.0285\n",
      "tensor([[23.4052]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [17/200], Loss: 0.0294\n",
      "tensor([[23.4085]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [18/200], Loss: 0.0284\n",
      "tensor([[23.4072]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [19/200], Loss: 0.0300\n",
      "tensor([[23.4187]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [20/200], Loss: 0.0282\n",
      "tensor([[23.4105]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [21/200], Loss: 0.0287\n",
      "tensor([[23.4270]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [22/200], Loss: 0.0266\n",
      "tensor([[23.4166]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [23/200], Loss: 0.0261\n",
      "tensor([[23.4303]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [24/200], Loss: 0.0277\n",
      "tensor([[23.4278]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [25/200], Loss: 0.0290\n",
      "tensor([[23.4300]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [26/200], Loss: 0.0387\n",
      "tensor([[23.4451]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [27/200], Loss: 0.0417\n",
      "tensor([[23.4311]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [28/200], Loss: 0.0528\n",
      "tensor([[23.4636]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [29/200], Loss: 0.0498\n",
      "tensor([[23.4310]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [30/200], Loss: 0.0540\n",
      "tensor([[23.4756]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [31/200], Loss: 0.0461\n",
      "tensor([[23.4260]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [32/200], Loss: 0.0499\n",
      "tensor([[23.4624]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [33/200], Loss: 0.1000\n",
      "tensor([[23.3400]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [34/200], Loss: 0.1415\n",
      "tensor([[23.4457]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [35/200], Loss: 0.4166\n",
      "tensor([[22.8937]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [36/200], Loss: 0.5088\n",
      "tensor([[23.4392]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [37/200], Loss: 0.7286\n",
      "tensor([[23.5891]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [38/200], Loss: 0.7787\n",
      "tensor([[23.3186]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [39/200], Loss: 0.4692\n",
      "tensor([[22.5690]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [40/200], Loss: 0.5471\n",
      "tensor([[22.2339]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [41/200], Loss: 0.7637\n",
      "tensor([[22.8151]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [42/200], Loss: 0.6063\n",
      "tensor([[23.3660]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [43/200], Loss: 0.9634\n",
      "tensor([[23.2570]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [44/200], Loss: 0.6080\n",
      "tensor([[22.8118]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [45/200], Loss: 0.9189\n",
      "tensor([[20.6386]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [46/200], Loss: 0.5784\n",
      "tensor([[23.1796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [47/200], Loss: 0.2372\n",
      "tensor([[23.1058]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [48/200], Loss: 0.1463\n",
      "tensor([[23.2335]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [49/200], Loss: 0.1518\n",
      "tensor([[23.1278]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [50/200], Loss: 0.1492\n",
      "tensor([[23.2727]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [51/200], Loss: 0.1429\n",
      "tensor([[23.2350]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [52/200], Loss: 0.1382\n",
      "tensor([[23.2751]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [53/200], Loss: 0.1208\n",
      "tensor([[23.2825]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [54/200], Loss: 0.1111\n",
      "tensor([[23.2827]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [55/200], Loss: 0.0984\n",
      "tensor([[23.3139]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [56/200], Loss: 0.0860\n",
      "tensor([[23.2899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [57/200], Loss: 0.0780\n",
      "tensor([[23.3391]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [58/200], Loss: 0.0639\n",
      "tensor([[23.2961]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [59/200], Loss: 0.0592\n",
      "tensor([[23.3610]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [60/200], Loss: 0.0446\n",
      "tensor([[23.3033]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [61/200], Loss: 0.0428\n",
      "tensor([[23.3806]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [62/200], Loss: 0.0326\n",
      "tensor([[23.3248]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [63/200], Loss: 0.0341\n",
      "tensor([[23.3821]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [64/200], Loss: 0.0444\n",
      "tensor([[23.3667]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [65/200], Loss: 0.0528\n",
      "tensor([[23.3559]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [66/200], Loss: 0.0770\n",
      "tensor([[23.3834]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [67/200], Loss: 0.0712\n",
      "tensor([[23.3228]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [68/200], Loss: 0.0707\n",
      "tensor([[23.4162]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [69/200], Loss: 0.0534\n",
      "tensor([[23.3037]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/200], Loss: 0.0524\n",
      "tensor([[23.4191]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [71/200], Loss: 0.0564\n",
      "tensor([[23.3866]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [72/200], Loss: 0.0784\n",
      "tensor([[23.3895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [73/200], Loss: 0.1408\n",
      "tensor([[23.4010]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [74/200], Loss: 0.1714\n",
      "tensor([[23.3195]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [75/200], Loss: 0.1446\n",
      "tensor([[23.4591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [76/200], Loss: 0.1126\n",
      "tensor([[23.3081]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [77/200], Loss: 0.0714\n",
      "tensor([[23.4410]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [78/200], Loss: 0.0580\n",
      "tensor([[23.3114]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [79/200], Loss: 0.0761\n",
      "tensor([[23.4238]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [80/200], Loss: 0.2295\n",
      "tensor([[22.7694]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [81/200], Loss: 0.1906\n",
      "tensor([[23.0708]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [82/200], Loss: 0.1564\n",
      "tensor([[23.3711]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [83/200], Loss: 0.2781\n",
      "tensor([[22.9664]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [84/200], Loss: 0.4279\n",
      "tensor([[23.2625]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [85/200], Loss: 0.5693\n",
      "tensor([[23.4274]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [86/200], Loss: 0.6465\n",
      "tensor([[23.3101]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [87/200], Loss: 0.5599\n",
      "tensor([[23.1476]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [88/200], Loss: 0.8193\n",
      "tensor([[23.2758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [89/200], Loss: 0.7600\n",
      "tensor([[23.5599]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [90/200], Loss: 0.1315\n",
      "tensor([[23.3981]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [91/200], Loss: 0.0658\n",
      "tensor([[23.4234]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [92/200], Loss: 0.0667\n",
      "tensor([[23.3623]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [93/200], Loss: 0.0743\n",
      "tensor([[23.3939]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [94/200], Loss: 0.0833\n",
      "tensor([[23.4083]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [95/200], Loss: 0.0852\n",
      "tensor([[23.3926]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [96/200], Loss: 0.0804\n",
      "tensor([[23.4385]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [97/200], Loss: 0.0768\n",
      "tensor([[23.3960]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [98/200], Loss: 0.0665\n",
      "tensor([[23.4513]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [99/200], Loss: 0.0601\n",
      "tensor([[23.4019]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [100/200], Loss: 0.0514\n",
      "tensor([[23.4586]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [101/200], Loss: 0.0440\n",
      "tensor([[23.4095]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [102/200], Loss: 0.0381\n",
      "tensor([[23.4632]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [103/200], Loss: 0.0313\n",
      "tensor([[23.4195]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [104/200], Loss: 0.0287\n",
      "tensor([[23.4648]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [105/200], Loss: 0.0257\n",
      "tensor([[23.4350]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [106/200], Loss: 0.0273\n",
      "tensor([[23.4631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [107/200], Loss: 0.0314\n",
      "tensor([[23.4621]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [108/200], Loss: 0.0359\n",
      "tensor([[23.4593]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [109/200], Loss: 0.0427\n",
      "tensor([[23.4978]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [110/200], Loss: 0.0437\n",
      "tensor([[23.4558]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [111/200], Loss: 0.0407\n",
      "tensor([[23.5171]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [112/200], Loss: 0.0340\n",
      "tensor([[23.4538]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [113/200], Loss: 0.0321\n",
      "tensor([[23.5071]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [114/200], Loss: 0.0450\n",
      "tensor([[23.4727]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [115/200], Loss: 0.0726\n",
      "tensor([[23.4766]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [116/200], Loss: 0.1338\n",
      "tensor([[23.5746]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [117/200], Loss: 0.1777\n",
      "tensor([[23.4518]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [118/200], Loss: 0.1348\n",
      "tensor([[23.5760]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [119/200], Loss: 0.1028\n",
      "tensor([[23.3934]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [120/200], Loss: 0.0772\n",
      "tensor([[23.5037]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [121/200], Loss: 0.1783\n",
      "tensor([[23.4248]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [122/200], Loss: 0.2931\n",
      "tensor([[23.3419]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [123/200], Loss: 0.4101\n",
      "tensor([[23.6189]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [124/200], Loss: 0.4239\n",
      "tensor([[23.3841]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [125/200], Loss: 0.2034\n",
      "tensor([[23.5475]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [126/200], Loss: 0.1099\n",
      "tensor([[23.4029]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [127/200], Loss: 0.0945\n",
      "tensor([[23.5505]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [128/200], Loss: 0.0755\n",
      "tensor([[23.4786]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [129/200], Loss: 0.1106\n",
      "tensor([[23.4717]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [130/200], Loss: 0.1991\n",
      "tensor([[23.6027]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [131/200], Loss: 0.2481\n",
      "tensor([[23.4358]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [132/200], Loss: 0.1751\n",
      "tensor([[23.5456]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [133/200], Loss: 0.1582\n",
      "tensor([[23.4018]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [134/200], Loss: 0.1357\n",
      "tensor([[23.5932]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [135/200], Loss: 0.0948\n",
      "tensor([[23.5020]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [136/200], Loss: 0.0475\n",
      "tensor([[23.5591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/200], Loss: 0.0376\n",
      "tensor([[23.4955]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [138/200], Loss: 0.0367\n",
      "tensor([[23.5480]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [139/200], Loss: 0.0542\n",
      "tensor([[23.4932]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [140/200], Loss: 0.0913\n",
      "tensor([[23.4698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [141/200], Loss: 0.2117\n",
      "tensor([[23.6326]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [142/200], Loss: 0.3113\n",
      "tensor([[23.4228]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [143/200], Loss: 0.2020\n",
      "tensor([[23.4509]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [144/200], Loss: 0.1704\n",
      "tensor([[23.3398]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [145/200], Loss: 0.2283\n",
      "tensor([[23.6145]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [146/200], Loss: 0.2969\n",
      "tensor([[23.4976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [147/200], Loss: 0.1371\n",
      "tensor([[23.3441]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [148/200], Loss: 0.2842\n",
      "tensor([[23.6305]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [149/200], Loss: 0.4407\n",
      "tensor([[23.3240]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [150/200], Loss: 0.3195\n",
      "tensor([[23.6094]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [151/200], Loss: 0.2158\n",
      "tensor([[23.4390]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [152/200], Loss: 0.1791\n",
      "tensor([[23.2679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [153/200], Loss: 0.4002\n",
      "tensor([[23.1461]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [154/200], Loss: 0.5884\n",
      "tensor([[23.1479]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [155/200], Loss: 0.6727\n",
      "tensor([[23.4062]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [156/200], Loss: 0.5890\n",
      "tensor([[23.2727]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [157/200], Loss: 0.7210\n",
      "tensor([[22.0162]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [158/200], Loss: 0.5864\n",
      "tensor([[23.4727]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [159/200], Loss: 0.6849\n",
      "tensor([[22.5699]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [160/200], Loss: 0.6532\n",
      "tensor([[23.5273]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [161/200], Loss: 0.5055\n",
      "tensor([[21.4837]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [162/200], Loss: 0.2078\n",
      "tensor([[23.5503]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [163/200], Loss: 0.3268\n",
      "tensor([[23.6206]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [164/200], Loss: 0.4015\n",
      "tensor([[23.5803]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [165/200], Loss: 0.2542\n",
      "tensor([[23.2483]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [166/200], Loss: 0.1851\n",
      "tensor([[23.4867]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [167/200], Loss: 0.2257\n",
      "tensor([[23.6961]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [168/200], Loss: 0.1946\n",
      "tensor([[23.5610]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [169/200], Loss: 0.0925\n",
      "tensor([[23.6281]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [170/200], Loss: 0.0380\n",
      "tensor([[23.4883]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [171/200], Loss: 0.0304\n",
      "tensor([[23.5621]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [172/200], Loss: 0.0292\n",
      "tensor([[23.5402]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [173/200], Loss: 0.0273\n",
      "tensor([[23.5444]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [174/200], Loss: 0.0266\n",
      "tensor([[23.5483]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [175/200], Loss: 0.0248\n",
      "tensor([[23.5443]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [176/200], Loss: 0.0244\n",
      "tensor([[23.5522]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [177/200], Loss: 0.0230\n",
      "tensor([[23.5463]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [178/200], Loss: 0.0228\n",
      "tensor([[23.5554]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [179/200], Loss: 0.0217\n",
      "tensor([[23.5494]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [180/200], Loss: 0.0215\n",
      "tensor([[23.5582]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [181/200], Loss: 0.0208\n",
      "tensor([[23.5535]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [182/200], Loss: 0.0205\n",
      "tensor([[23.5611]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [183/200], Loss: 0.0201\n",
      "tensor([[23.5588]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [184/200], Loss: 0.0197\n",
      "tensor([[23.5643]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [185/200], Loss: 0.0195\n",
      "tensor([[23.5651]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [186/200], Loss: 0.0191\n",
      "tensor([[23.5683]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [187/200], Loss: 0.0189\n",
      "tensor([[23.5738]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [188/200], Loss: 0.0185\n",
      "tensor([[23.5749]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [189/200], Loss: 0.0183\n",
      "tensor([[23.5785]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [190/200], Loss: 0.0181\n",
      "tensor([[23.5864]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [191/200], Loss: 0.0178\n",
      "tensor([[23.5826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [192/200], Loss: 0.0175\n",
      "tensor([[23.5907]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [193/200], Loss: 0.0175\n",
      "tensor([[23.5925]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [194/200], Loss: 0.0170\n",
      "tensor([[23.6026]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [195/200], Loss: 0.0168\n",
      "tensor([[23.6060]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [196/200], Loss: 0.0167\n",
      "tensor([[23.6029]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [197/200], Loss: 0.0161\n",
      "tensor([[23.5989]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [198/200], Loss: 0.0159\n",
      "tensor([[23.6081]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [199/200], Loss: 0.0157\n",
      "tensor([[23.6155]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n",
      "Epoch [200/200], Loss: 0.0157\n",
      "tensor([[23.6198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([24.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i in range(x.size(0)):\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x_data = x[i]\n",
    "        y_data = y[i]\n",
    "        \n",
    "        x_data = x_data.unsqueeze(0)\n",
    "        x_data = x_data.unsqueeze(2).to(device)\n",
    "        y_data = y_data.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x_data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, y_data)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "    print(outputs)\n",
    "    print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42d47ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.0899]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3, 4, 5])\n",
    "x = x.unsqueeze(0).unsqueeze(2).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d8ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_env)",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
